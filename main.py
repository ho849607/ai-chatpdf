# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
import os
import streamlit as st
from io import BytesIO
from dotenv import load_dotenv
import pdfplumber
from langchain.chat_models import ChatOpenAI
from langchain.schema import HumanMessage
import openai
from pathlib import Path
import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords

# ì´ˆê¸° ì„¤ì •
nltk.download('punkt')
nltk.download('stopwords')

# í•œêµ­ì–´ ë¶ˆìš©ì–´ ë¦¬ìŠ¤íŠ¸ ì •ì˜
korean_stopwords = ['ì´', 'ê·¸', 'ì €', 'ê²ƒ', 'ìˆ˜', 'ë“±', 'ë“¤', 'ë°', 'ë”', 'ë¡œ', 'ë¥¼', 'ì—',
                    'ì˜', 'ì€', 'ëŠ”', 'ê°€', 'ì™€', 'ê³¼', 'í•˜ë‹¤', 'ìˆë‹¤', 'ë˜ë‹¤', 'ì´ë‹¤',
                    'ìœ¼ë¡œ', 'ì—ì„œ', 'ê¹Œì§€', 'ë¶€í„°', 'ê¹Œì§€', 'ë§Œ', 'í•˜ë‹¤', 'ê·¸ë¦¬ê³ ', 'í•˜ì§€ë§Œ', 'ê·¸ëŸ¬ë‚˜']

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
dotenv_path = Path('.env')
load_dotenv(dotenv_path=dotenv_path)

# API í‚¤ ì„¤ì •
openai_api_key = os.getenv("OPENAI_API_KEY")
if not openai_api_key:
    openai_api_key = st.sidebar.text_input("OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.", type="password")
    if not openai_api_key:
        st.error("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        st.stop()

openai.api_key = openai_api_key

# ì œëª© ì„¤ì •
st.title("ğŸ“š PDF í•™ìŠµ ë„ìš°ë¯¸")
st.write("---")

# 'lang' ì´ˆê¸°í™”
if 'lang' not in st.session_state:
    st.session_state.lang = 'english'  # ê¸°ë³¸ ì–¸ì–´ë¥¼ ì˜ì–´ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.

# ì €ì‘ê¶Œ ìœ ì˜ì‚¬í•­ ê²½ê³  ë©”ì‹œì§€ ì¶”ê°€
st.warning("ì €ì‘ë¬¼ì„ ë¶ˆë²• ë³µì œí•˜ì—¬ ê²Œì‹œí•˜ëŠ” ê²½ìš° ë‹¹ì‚¬ëŠ” ì±…ì„ì§€ì§€ ì•Šìœ¼ë©°, ì €ì‘ê¶Œë²•ì— ìœ ì˜í•˜ì—¬ íŒŒì¼ì„ ì˜¬ë ¤ì£¼ì„¸ìš”.")

# ì‚¬ì´ë“œë°”ì— ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ ì¶”ê°€
st.sidebar.title("ğŸ’¬ GPTì™€ì˜ ì±„íŒ…")
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

def chat_interface():
    for chat in st.session_state.chat_history:
        if chat["role"] == "user":
            st.markdown(f"**ğŸ‘¤ ì‚¬ìš©ì:** {chat['message']}")
        else:
            st.markdown(f"**ğŸ¤– GPT:** {chat['message']}")

    if st.session_state.lang == 'korean':
        user_chat_input = st.text_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”:", key="user_chat_input")
    else:
        user_chat_input = st.text_input("Enter your message:", key="user_chat_input")

    if user_chat_input:
        add_chat_message("user", user_chat_input)
        with st.spinner("GPTê°€ ì‘ë‹µ ì¤‘ì…ë‹ˆë‹¤..."):
            gpt_response = ask_gpt_question(user_chat_input, st.session_state.lang)
            add_chat_message("assistant", gpt_response)
            st.markdown(f"**ğŸ¤– GPT:** {gpt_response}")

# ì±„íŒ… ë©”ì‹œì§€ ì¶”ê°€ í•¨ìˆ˜
def add_chat_message(role, message):
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []
    st.session_state.chat_history.append({"role": role, "message": message})

# PDFë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
def pdf_to_text(upload_file):
    try:
        with pdfplumber.open(BytesIO(upload_file.read())) as pdf:
            pages = []
            for i, page in enumerate(pdf.pages):
                text = page.extract_text()
                if text:
                    pages.append(f"<PAGE{i+1}>\n{text}")
            return "\n".join(pages)
    except Exception as e:
        st.error(f"PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return ""

# ì–¸ì–´ ê°ì§€ í•¨ìˆ˜ (OpenAI API í™œìš©)
def detect_language(text):
    try:
        llm = ChatOpenAI(
            model_name="gpt-3.5-turbo",
            temperature=0
        )
        prompt = f"ë‹¤ìŒ í…ìŠ¤íŠ¸ì˜ ì–¸ì–´ë¥¼ ISO 639-1 ì½”ë“œë¡œ ê°ì§€í•´ ì£¼ì„¸ìš” (ì˜ˆ: 'en'ì€ ì˜ì–´, 'ko'ëŠ” í•œêµ­ì–´):\n\n{text[:500]}"
        messages = [HumanMessage(content=prompt)]
        response = llm(messages)
        language_code = response.content.strip().lower()
        language_code = language_code.split()[0]
        return language_code
    except Exception as e:
        st.error(f"ì–¸ì–´ ê°ì§€ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return "unknown"

# ìš”ì•½ ìƒì„± í•¨ìˆ˜ (ì„œë¡ , ë³¸ë¡ , ê²°ë¡  êµ¬ì¡°ë¡œ)
def summarize_pdf(text, language):
    llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0)
    if language == 'korean':
        prompt = f"ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ì½ê³  ì„œë¡ , ë³¸ë¡ , ê²°ë¡ ìœ¼ë¡œ êµ¬ì„±ëœ ìì„¸í•œ ìš”ì•½ì„ ì‘ì„±í•´ ì£¼ì„¸ìš”:\n\n{text}"
    else:
        prompt = f"Read the following text and write a detailed summary structured with an introduction, main body, and conclusion:\n\n{text}"
    messages = [HumanMessage(content=prompt)]
    response = llm(messages)
    return response.content.strip()

# í•µì‹¬ ìš”ì•½ ë‹¨ì–´ ì¶”ì¶œ í•¨ìˆ˜ (ì¶œì²˜ í¬í•¨)
def extract_key_summary_words_with_sources(text, language):
    llm = ChatOpenAI(
        model_name="gpt-3.5-turbo",
        temperature=0
    )
    if language == 'korean':
        prompt = f"""ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ ì¤‘ìš”í•œ í‚¤ì›Œë“œ 5~10ê°œë¥¼ ì¶”ì¶œí•˜ê³ , ê° í‚¤ì›Œë“œì˜ ì¶œì²˜(í˜ì´ì§€ ë²ˆí˜¸ ë˜ëŠ” ìœ„ì¹˜)ë¥¼ í‘œì‹œí•´ ì£¼ì„¸ìš”. ê²°ê³¼ëŠ” ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì œê³µí•´ ì£¼ì„¸ìš”:

í‚¤ì›Œë“œ1 (ì¶œì²˜)
í‚¤ì›Œë“œ2 (ì¶œì²˜)
...

í…ìŠ¤íŠ¸:
{text}
"""
    else:
        prompt = f"""Extract 5 to 10 important keywords from the following text and indicate their sources (page number or location). Provide the results in the following format:

Keyword1 (Source)
Keyword2 (Source)
...

Text:
{text}
"""
    messages = [HumanMessage(content=prompt)]
    response = llm(messages)
    keywords_with_sources = response.content.strip()
    return keywords_with_sources

# ë‹¨ì–´ ì¶”ì¶œ ë° ê²€ìƒ‰ í•¨ìˆ˜
def extract_and_search_terms(summary_text, extracted_text, language='english'):
    llm = ChatOpenAI(
        model_name="gpt-3.5-turbo",
        temperature=0
    )
    if language == 'korean':
        prompt = f"ë‹¤ìŒ ìš”ì•½ì—ì„œ ì¤‘ìš”í•œ ìš©ì–´ 5~10ê°œë¥¼ ì¶”ì¶œí•˜ê³ , ê° ìš©ì–´ì— ëŒ€í•œ ìì„¸í•œ ì •ì˜ì™€ í•´ë‹¹ ìš©ì–´ê°€ í…ìŠ¤íŠ¸ ë‚´ì—ì„œ ì–¸ê¸‰ëœ í˜ì´ì§€ ë²ˆí˜¸ë¥¼ ì œê³µí•´ ì£¼ì„¸ìš”:\n\n{summary_text}"
    else:
        prompt = f"Extract 5 to 10 important terms from the following summary and provide a detailed definition and the page numbers where each term is mentioned in the text:\n\n{summary_text}"
    messages = [HumanMessage(content=prompt)]
    response = llm(messages)
    term_info = response.content.strip()
    return term_info

# í€´ì¦ˆ ìƒì„± í•¨ìˆ˜
def generate_quiz(text, language):
    llm = ChatOpenAI(
        model_name="gpt-3.5-turbo",
        temperature=0.5
    )
    if language == 'korean':
        prompt = f"ë‹¤ìŒ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ 5ê°œì˜ ê°ê´€ì‹ í€´ì¦ˆ ë¬¸ì œë¥¼ ë§Œë“¤ì–´ ì£¼ì„¸ìš”. ê° ì§ˆë¬¸ì€ 4ê°œì˜ ì„ íƒì§€ë¥¼ í¬í•¨í•˜ê³  ì •ë‹µì„ í‘œì‹œí•´ ì£¼ì„¸ìš”:\n\n{text}"
    else:
        prompt = f"Based on the following content, create 5 multiple-choice quiz questions. Each question should have 4 options and indicate the correct answer:\n\n{text}"
    messages = [HumanMessage(content=prompt)]
    response = llm(messages)
    return response.content

# ì‹œí—˜ ë¬¸ì œ ìƒì„± í•¨ìˆ˜
def generate_exam_questions(text, language):
    llm = ChatOpenAI(
        model_name="gpt-3.5-turbo",
        temperature=0.5
    )
    if language == 'korean':
        prompt = f"ë‹¤ìŒ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì¤‘ìš”í•œ ì‹œí—˜ ë¬¸ì œ 5ê°œë¥¼ ë§Œë“¤ì–´ ì£¼ì„¸ìš”:\n\n{text}"
    else:
        prompt = f"Based on the following content, create 5 important exam questions:\n\n{text}"
    messages = [HumanMessage(content=prompt)]
    response = llm(messages)
    return response.content

# GPTê°€ ì‚¬ìš©ìì—ê²Œ ì§ˆë¬¸ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
def generate_questions_for_user(text, language):
    llm = ChatOpenAI(
        model_name="gpt-3.5-turbo",
        temperature=0.5
    )
    if language == 'korean':
        prompt = f"ë‹¤ìŒ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ìê°€ ë” ê¹Šì´ ìƒê°í•  ìˆ˜ ìˆë„ë¡ 3ê°œì˜ ì§ˆë¬¸ì„ ë§Œë“¤ì–´ ì£¼ì„¸ìš”:\n\n{text}"
    else:
        prompt = f"Based on the following content, generate 3 thoughtful questions to ask the user for a deeper understanding:\n\n{text}"
    messages = [HumanMessage(content=prompt)]
    response = llm(messages)
    questions = response.content.strip().split('\n')
    return questions

# ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ GPT ì‘ë‹µ í•¨ìˆ˜
def ask_gpt_question(question, language):
    llm = ChatOpenAI(
        model_name="gpt-3.5-turbo",
        temperature=0.5
    )
    if language == 'korean':
        prompt = f"ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µë³€í•´ ì£¼ì„¸ìš”: {question}"
    else:
        prompt = question
    messages = [HumanMessage(content=prompt)]
    response = llm(messages)
    return response.content

# íŒŒì¼ ì—…ë¡œë“œ ë° ë°ì´í„° ì²˜ë¦¬
if "processed" not in st.session_state:
    st.session_state.processed = False

uploaded_file = st.file_uploader("PDF íŒŒì¼ì„ ì˜¬ë ¤ì£¼ì„¸ìš”", type=['pdf'])

# ì—¬ê¸°ì—ì„œ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ë¥¼ PDF ì—…ë¡œë” ë°”ë¡œ ì•„ë˜ì— í‘œì‹œí•©ë‹ˆë‹¤.
chat_interface()

if uploaded_file is not None:
    if uploaded_file.type == "application/pdf":
        extracted_text = pdf_to_text(uploaded_file)

        if not extracted_text.strip():
            st.error("PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ PDFë¥¼ ì‹œë„í•´ë³´ì„¸ìš”.")
        else:
            st.success("PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.")
            language_code = detect_language(extracted_text)
            if language_code == 'ko':
                lang = 'korean'
                language_name = 'í•œêµ­ì–´'
            elif language_code == 'en':
                lang = 'english'
                language_name = 'ì˜ì–´'
            else:
                lang = 'english'  # ê¸°ë³¸ê°’ì„ ì˜ì–´ë¡œ ì„¤ì •
                language_name = 'ì•Œ ìˆ˜ ì—†ìŒ (ì˜ì–´ë¡œ ì§„í–‰í•©ë‹ˆë‹¤)'

            st.write(f"### ê°ì§€ëœ ì–¸ì–´: {language_name}")
            st.session_state.lang = lang
            st.session_state.extracted_text = extracted_text

            # ìš”ì•½ ìƒì„± ë° ì €ì¥
            with st.spinner("ìš”ì•½ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                summary = summarize_pdf(extracted_text, lang)
                st.write("## ìš”ì•½ ê²°ê³¼")
                st.write(summary)
                st.session_state.summary = summary

            # í•µì‹¬ ìš”ì•½ ë‹¨ì–´ ì¶”ì¶œ (ì¶œì²˜ í¬í•¨)
            with st.spinner("í•µì‹¬ ìš”ì•½ ë‹¨ì–´ë¥¼ ì¶”ì¶œí•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                key_summary_words = extract_key_summary_words_with_sources(extracted_text, lang)
                st.write("## í•µì‹¬ ìš”ì•½ ë‹¨ì–´ ë° ì¶œì²˜")
                st.write(key_summary_words)
                st.session_state.keywords = key_summary_words

            # ì¤‘ìš” ë‹¨ì–´ ì •ë³´ ì¶”ì¶œ
            with st.spinner("ìš”ì•½ ë‚´ ë‹¨ì–´ë¥¼ ê²€ìƒ‰í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                term_info = extract_and_search_terms(summary, extracted_text, language=lang)
                st.write("## ìš”ì•½ ë‚´ ì¤‘ìš”í•œ ë‹¨ì–´ ì •ë³´")
                st.write(term_info)

            # í€´ì¦ˆ ìƒì„±
            with st.spinner("í€´ì¦ˆë¥¼ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                quiz = generate_quiz(extracted_text, lang)
                st.write("## ìƒì„±ëœ í€´ì¦ˆ")
                st.write(quiz)

            # ì‹œí—˜ ë¬¸ì œ ìƒì„±
            with st.spinner("ì‹œí—˜ ë¬¸ì œë¥¼ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                exam_questions = generate_exam_questions(extracted_text, lang)
                st.write("## ìƒì„±ëœ ì‹œí—˜ ë¬¸ì œ")
                st.write(exam_questions)

            # GPTê°€ ì‚¬ìš©ìì—ê²Œ ì§ˆë¬¸ ìƒì„±
            with st.spinner("GPTê°€ ì§ˆë¬¸ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                gpt_questions = generate_questions_for_user(extracted_text, lang)
                st.session_state.gpt_questions = gpt_questions

            st.session_state.processed = True
    else:
        st.error("ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. PDF íŒŒì¼ë§Œ ì˜¬ë ¤ì£¼ì„¸ìš”.")

# í‚¤ì›Œë“œ ê²€ìƒ‰ ê¸°ëŠ¥ ì¶”ê°€
if st.session_state.get("processed", False):
    st.write("---")
    if st.session_state.lang == 'korean':
        st.write("## ğŸ” í‚¤ì›Œë“œ ê²€ìƒ‰")
        search_query = st.text_input("ê²€ìƒ‰í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”:")
    else:
        st.write("## ğŸ” Keyword Search")
        search_query = st.text_input("Enter a keyword to search:")
    if search_query:
        # ê²€ìƒ‰ ê¸°ëŠ¥ êµ¬í˜„
        search_results = []
        for line in st.session_state.extracted_text.split('\n'):
            if search_query.lower() in line.lower():
                search_results.append(line.strip())
        if search_results:
            if st.session_state.lang == 'korean':
                st.write("### ê²€ìƒ‰ ê²°ê³¼:")
            else:
                st.write("### Search Results:")
            for result in search_results:
                st.write(f"- {result}")
        else:
            if st.session_state.lang == 'korean':
                st.write("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.write("No results found.")

# GPTê°€ ì‚¬ìš©ìì—ê²Œ ì§ˆë¬¸í•˜ê³  ì‚¬ìš©ì ì‘ë‹µ ë°›ê¸°
if st.session_state.get("processed", False):
    st.write("---")
    if st.session_state.lang == 'korean':
        st.write("## GPTê°€ ë‹¹ì‹ ì—ê²Œ ì§ˆë¬¸í•©ë‹ˆë‹¤")
    else:
        st.write("## GPT has questions for you")
    if "gpt_questions" in st.session_state:
        for idx, question in enumerate(st.session_state.gpt_questions):
            user_answer = st.text_input(f"**{question}**", key=f"gpt_question_{idx}")
            if user_answer:
                with st.spinner("GPTê°€ ì‘ë‹µì„ ê²€í†  ì¤‘ì…ë‹ˆë‹¤..."):
                    if st.session_state.lang == 'korean':
                        feedback_prompt = f"{question}\n\nì‚¬ìš©ìì˜ ë‹µë³€: {user_answer}\n\nì´ì— ëŒ€í•´ í”¼ë“œë°±ì„ ì œê³µí•´ ì£¼ì„¸ìš”."
                    else:
                        feedback_prompt = f"{question}\n\nUser's answer: {user_answer}\n\nPlease provide feedback on this."
                    feedback = ask_gpt_question(feedback_prompt, st.session_state.lang)
                    if st.session_state.lang == 'korean':
                        st.write("### GPTì˜ í”¼ë“œë°±")
                    else:
                        st.write("### GPT's Feedback")
                    st.write(feedback)

# í•˜ë‹¨ì— ì£¼ì˜ ë¬¸êµ¬ ì¶”ê°€
st.write("---")
st.info("**ChatGPTëŠ” ì‹¤ìˆ˜ë¥¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¤‘ìš”í•œ ì •ë³´ë¥¼ í™•ì¸í•˜ì„¸ìš”.**")
