import os
import nltk

# (1) NLTK_DATA ê²½ë¡œë¥¼ /tmp ë¡œ ì§€ì • (ì“°ê¸° ê°€ëŠ¥)
nltk_data_dir = "/tmp/nltk_data"
os.makedirs(nltk_data_dir, exist_ok=True)  # ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±

# NLTKê°€ /tmp/nltk_dataë¥¼ ì°¸ì¡°í•˜ë„ë¡ ì„¤ì •
os.environ["NLTK_DATA"] = nltk_data_dir
nltk.data.path.append(nltk_data_dir)

# stopwords ë‹¤ìš´ë¡œë“œ ì‹œë„
nltk.download("stopwords", download_dir=nltk_data_dir)

import streamlit as st
from io import BytesIO
from dotenv import load_dotenv
import openai
from pathlib import Path
import hashlib
# ë’¤ìª½ì— nltk ì¬-importê°€ ìˆì–´ë„ ì¶©ëŒì€ ì—†ìœ¼ë‹ˆ ê·¸ëŒ€ë¡œ ë‘¬ë„ ë©ë‹ˆë‹¤.
import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords

# docx2txt ì„¤ì¹˜ í™•ì¸
try:
    import docx2txt
    DOCX_ENABLED = True
except ImportError:
    DOCX_ENABLED = False

# ì´ˆê¸° NLTK ë‹¤ìš´ë¡œë“œ (tokenizer, stopwordsê°€ ì—†ëŠ” ê²½ìš° ë‹¤ìš´ë¡œë“œ)
try:
    nltk.data.find('tokenizers/punkt')
except LookupError:
    nltk.download('punkt', download_dir=nltk_data_dir)

try:
    nltk.data.find('corpora/stopwords')
except LookupError:
    nltk.download('stopwords', download_dir=nltk_data_dir)

# ì‚¬ìš©ì ì •ì˜ í•œêµ­ì–´ ìŠ¤í†±ì›Œë“œ
korean_stopwords = [
    'ì´', 'ê·¸', 'ì €', 'ê²ƒ', 'ìˆ˜', 'ë“±', 'ë“¤', 'ë°', 'ë”', 'ë¡œ', 'ë¥¼', 'ì—',
    'ì˜', 'ì€', 'ëŠ”', 'ê°€', 'ì™€', 'ê³¼', 'í•˜ë‹¤', 'ìˆë‹¤', 'ë˜ë‹¤', 'ì´ë‹¤',
    'ìœ¼ë¡œ', 'ì—ì„œ', 'ê¹Œì§€', 'ë¶€í„°', 'ë§Œ', 'ê·¸ë¦¬ê³ ', 'í•˜ì§€ë§Œ', 'ê·¸ëŸ¬ë‚˜'
]
# NLTK ì˜ì–´ ìŠ¤í†±ì›Œë“œ + í•œêµ­ì–´ ìŠ¤í†±ì›Œë“œ ë³‘í•©
english_stopwords = set(stopwords.words('english'))
korean_stopwords_set = set(korean_stopwords)
final_stopwords = english_stopwords.union(korean_stopwords_set)

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="studyhelper", layout="centered")

###############################################################################
# .env ë¡œë“œ ë° OpenAI API í‚¤ ì„¤ì •
###############################################################################
dotenv_path = Path('.env')
load_dotenv(dotenv_path=dotenv_path)

openai_api_key = os.getenv("OPENAI_API_KEY")
if not openai_api_key:
    openai_api_key = st.sidebar.text_input("OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.", type="password")
    if not openai_api_key:
        st.error("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        st.stop()

# OpenAI API í‚¤ ì§ì ‘ ì„¤ì •
openai.api_key = openai_api_key

# (ì¤‘ìš”) ì•„ë˜ 3ì¤„ì€ ì œê±°(ë˜ëŠ” ì£¼ì„ ì²˜ë¦¬)í•´ì„œ 'NoneType' ì˜¤ë¥˜ ë°©ì§€
# openai.api_base = "https://api.openai.com/v1"
# openai.api_type = None
# openai.api_version = None

###############################################################################
# ë²„ì „ í™•ì¸ (ë¡œê·¸ì— í‘œì‹œ)
###############################################################################
try:
    st.write(f"OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ì „: {openai.__version__}")
except:
    pass

###############################################################################
# GPT ì—°ë™ í•¨ìˆ˜ (êµ¬ë²„ì „ ChatCompletion)
###############################################################################
def ask_gpt(prompt_text, model_name="gpt-4", temperature=0.0):
    """
    openai==0.28.x ì´í•˜ ë²„ì „ì—ì„œ:
    êµ¬ë²„ì „ API -> openai.ChatCompletion.create(...)
    """
    response = openai.ChatCompletion.create(
        model=model_name,
        messages=[
            {"role": "system", "content": "You are a helpful AI assistant."},
            {"role": "user", "content": prompt_text}
        ],
        temperature=temperature
    )
    return response.choices[0].message["content"].strip()

###############################################################################
# ê³ ê¸‰ ë¶„ì„(Chunk ë¶„í•  + ì¤‘ìš”ë„ í‰ê°€) í•¨ìˆ˜
###############################################################################
def chunk_text_by_heading(docx_text):
    """
    '===Heading:' ë§ˆì»¤ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¬¸ë‹¨ì„ ìª¼ê°œëŠ” ì˜ˆì‹œ.
    """
    lines = docx_text.split('\n')
    chunks = []
    current_chunk = []
    heading_title = "NoHeading"
    chunk_id = 0

    for line in lines:
        if line.strip().startswith("===Heading:"):
            if current_chunk:
                chunks.append({
                    "id": chunk_id,
                    "heading": heading_title,
                    "text": "\n".join(current_chunk)
                })
                chunk_id += 1
                current_chunk = []
            heading_title = line.replace("===Heading:", "").strip()
        else:
            current_chunk.append(line)

    if current_chunk:
        chunks.append({
            "id": chunk_id,
            "heading": heading_title,
            "text": "\n".join(current_chunk)
        })
    return chunks

def gpt_evaluate_importance(chunk_text, language='korean'):
    """
    1) Chunk ì¤‘ìš”ë„(1~5)
    2) í•œë‘ ë¬¸ì¥ ìš”ì•½
    """
    if language == 'korean':
        prompt = f"""
        ì•„ë˜ í…ìŠ¤íŠ¸ê°€ ìˆìŠµë‹ˆë‹¤. ì´ í…ìŠ¤íŠ¸ê°€ ì „ì²´ ë¬¸ì„œì—ì„œ ì–¼ë§ˆë‚˜ ì¤‘ìš”í•œì§€ 1~5 ì‚¬ì´ ì •ìˆ˜ë¡œ ê²°ì •í•˜ê³ ,
        í•œë‘ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”.

        í…ìŠ¤íŠ¸:
        {chunk_text}

        ì‘ë‹µ í˜•ì‹ ì˜ˆì‹œ:
        ì¤‘ìš”ë„: 4
        ìš”ì•½: ~~
        """
    else:
        prompt = f"""
        The following text is given. Please determine how important it is (1 to 5),
        and provide a one or two-sentence summary.

        Text:
        {chunk_text}

        Example response format:
        Importance: 4
        Summary: ...
        """

    response = ask_gpt(prompt, model_name="gpt-4", temperature=0.0)
    importance = 3
    short_summary = ""

    for line in response.split('\n'):
        if "ì¤‘ìš”ë„:" in line or "Importance:" in line:
            try:
                number_str = line.split(':')[-1].strip()
                importance = int(number_str)
            except:
                pass
        if "ìš”ì•½:" in line or "Summary:" in line:
            short_summary = line.split(':', 1)[-1].strip()

    return importance, short_summary

def docx_advanced_processing(docx_text, language='korean'):
    """
    1) ë¬¸ë‹¨/Heading ê¸°ì¤€ìœ¼ë¡œ chunk ë¶„í• 
    2) GPTë¡œ ê° chunk ì¤‘ìš”ë„/ìš”ì•½
    """
    chunks = chunk_text_by_heading(docx_text)
    combined_result = []

    for c in chunks:
        importance, short_summary = gpt_evaluate_importance(c["text"], language=language)
        c["importance"] = importance
        c["short_summary"] = short_summary
        combined_result.append(c)

    # chunkë³„ ê²°ê³¼ í•©ì¹¨
    final_summary_parts = []
    for c in combined_result:
        part = (
            f"=== [Chunk #{c['id']}] Heading: {c['heading']} ===\n"
            f"ì¤‘ìš”ë„: {c['importance']}\n"
            f"ìš”ì•½: {c['short_summary']}\n"
            f"ì›ë¬¸ ì¼ë¶€:\n{c['text'][:200]}...\n"
        )
        final_summary_parts.append(part)

    final_summary = "\n".join(final_summary_parts)
    return final_summary

###############################################################################
# ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
###############################################################################
def add_chat_message(role, message):
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []
    st.session_state.chat_history.append({"role": role, "message": message})

def chat_interface():
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []

    # ê¸°ì¡´ ì±„íŒ… ì´ë ¥ í‘œì‹œ
    for chat in st.session_state.chat_history:
        if chat["role"] == "user":
            with st.chat_message("user"):
                st.write(chat["message"])
        else:
            with st.chat_message("assistant"):
                st.write(chat["message"])

    user_chat_input = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”:")
    if user_chat_input:
        add_chat_message("user", user_chat_input)
        with st.chat_message("user"):
            st.write(user_chat_input)

        with st.spinner("GPTê°€ ì‘ë‹µ ì¤‘ì…ë‹ˆë‹¤..."):
            gpt_response = ask_gpt(user_chat_input, model_name="gpt-4", temperature=0.0)
            add_chat_message("assistant", gpt_response)
            with st.chat_message("assistant"):
                st.write(gpt_response)

###############################################################################
# DOCX í…ìŠ¤íŠ¸ ì¶”ì¶œ
###############################################################################
def docx_to_text(upload_file):
    if not DOCX_ENABLED:
        st.warning("docx2txtê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•Šì•„ .docx íŒŒì¼ì„ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return ""
    try:
        import docx2txt
        text = docx2txt.process(BytesIO(upload_file.getvalue()))
        return text if text else ""
    except Exception as e:
        st.error(f"DOCX íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return ""

###############################################################################
# ì»¤ë®¤ë‹ˆí‹°(ì•„ì´ë””ì–´ ê³µìœ  & íˆ¬ì)
###############################################################################
def community_investment_tab():
    st.header("ì•„ì´ë””ì–´ ê³µìœ  & íˆ¬ì ì»¤ë®¤ë‹ˆí‹°")

    if "community_ideas" not in st.session_state:
        st.session_state.community_ideas = []

    st.subheader("ìƒˆë¡œìš´ ì•„ì´ë””ì–´ ì œì•ˆí•˜ê¸°")
    idea_title = st.text_input("ì•„ì´ë””ì–´ ì œëª©", "")
    idea_content = st.text_area("ì•„ì´ë””ì–´ ë‚´ìš©(ê°„ëµ ì†Œê°œ)", "")

    if st.button("ì•„ì´ë””ì–´ ë“±ë¡"):
        if idea_title.strip() and idea_content.strip():
            st.session_state.community_ideas.append({
                "title": idea_title,
                "content": idea_content,
                "comments": [],
                "likes": 0,
                "dislikes": 0,
                "investment": 0
            })
            st.success("ì•„ì´ë””ì–´ê°€ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤!")
        else:
            st.warning("ì œëª©ê³¼ ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”.")

    st.write("---")
    st.subheader("ì»¤ë®¤ë‹ˆí‹° ì•„ì´ë””ì–´ ëª©ë¡")

    if len(st.session_state.community_ideas) == 0:
        st.write("ì•„ì§ ë“±ë¡ëœ ì•„ì´ë””ì–´ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        for idx, idea in enumerate(st.session_state.community_ideas):
            with st.expander(f"{idx+1}. {idea['title']}"):
                st.write(f"**ë‚´ìš©**: {idea['content']}")

                col1, col2, col3 = st.columns(3)
                with col1:
                    st.write(f"ğŸ‘ ì¢‹ì•„ìš”: {idea['likes']}")
                    if st.button(f"ì¢‹ì•„ìš” (ì•„ì´ë””ì–´ #{idx+1})"):
                        idea["likes"] += 1
                        st.experimental_rerun()

                with col2:
                    st.write(f"ğŸ‘ ì‹«ì–´ìš”: {idea['dislikes']}")
                    if st.button(f"ì‹«ì–´ìš” (ì•„ì´ë””ì–´ #{idx+1})"):
                        idea["dislikes"] += 1
                        st.experimental_rerun()

                with col3:
                    st.write(f"ğŸ’° í˜„ì¬ íˆ¬ìì•¡: {idea['investment']}")
                    invest_amount = st.number_input(
                        f"íˆ¬ì ê¸ˆì•¡ ì…ë ¥ (ì•„ì´ë””ì–´ #{idx+1})",
                        min_value=0,
                        step=10,
                        key=f"investment_input_{idx}"
                    )
                    if st.button(f"íˆ¬ìí•˜ê¸° (ì•„ì´ë””ì–´ #{idx+1})"):
                        idea["investment"] += invest_amount
                        st.success(f"{invest_amount}ë§Œí¼ íˆ¬ìí–ˆìŠµë‹ˆë‹¤!")
                        st.experimental_rerun()

                st.write("### ëŒ“ê¸€")
                if len(idea["comments"]) == 0:
                    st.write("ì•„ì§ ëŒ“ê¸€ì´ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    for c_idx, comment in enumerate(idea["comments"]):
                        st.write(f"- {comment}")

                comment_text = st.text_input(
                    f"ëŒ“ê¸€ ë‹¬ê¸° (ì•„ì´ë””ì–´ #{idx+1})",
                    key=f"comment_input_{idx}"
                )
                if st.button(f"ëŒ“ê¸€ ë“±ë¡ (ì•„ì´ë””ì–´ #{idx+1})"):
                    if comment_text.strip():
                        idea["comments"].append(comment_text.strip())
                        st.success("ëŒ“ê¸€ì´ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤!")
                        st.experimental_rerun()
                    else:
                        st.warning("ëŒ“ê¸€ ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”.")

                st.write("---")
                st.write("### GPT ì¶”ê°€ ê¸°ëŠ¥")

                if st.button(f"SWOT ë¶„ì„ (ì•„ì´ë””ì–´ #{idx+1})"):
                    with st.spinner("SWOT ë¶„ì„ ì¤‘..."):
                        prompt_swot = f"""
                        ì•„ë˜ ì•„ì´ë””ì–´ì— ëŒ€í•´ ê°„ëµí•˜ê²Œ SWOT(Strengths, Weaknesses, Opportunities, Threats)ì„ í•´ì£¼ì„¸ìš”.

                        ì•„ì´ë””ì–´:
                        {idea['content']}
                        """
                        swot_result = ask_gpt(prompt_swot, "gpt-4", 0.3)
                        st.write("**SWOT ë¶„ì„ ê²°ê³¼**:")
                        st.write(swot_result)

                if st.button(f"ì£¼ì œë³„ ë¶„ë¥˜ (ì•„ì´ë””ì–´ #{idx+1})"):
                    with st.spinner("ì•„ì´ë””ì–´ ì£¼ì œ ë¶„ë¥˜ ì¤‘..."):
                        prompt_category = f"""
                        ì•„ë˜ ì•„ì´ë””ì–´ê°€ ì–´ëŠ ë¶„ì•¼(ê¸°ìˆ , í‘¸ë“œ, êµìœ¡, ê¸ˆìœµ, ê±´ê°•, ê¸°íƒ€)ì¸ì§€ ì¶”ì •í•´ ì£¼ì„¸ìš”.
                        ê°„ë‹¨í•œ ê·¼ê±°ì™€ í•¨ê»˜ ì•Œë ¤ì£¼ë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤.

                        ì•„ì´ë””ì–´:
                        {idea['content']}
                        """
                        category_result = ask_gpt(prompt_category, "gpt-4", 0.3)
                        st.write("**ì£¼ì œë³„ ë¶„ë¥˜ ê²°ê³¼**:")
                        st.write(category_result)

                st.write("---")

###############################################################################
# ë©”ì¸ í•¨ìˆ˜
###############################################################################
def main():
    st.title("studyhelper")

    st.warning("ì €ì‘ê¶Œì— ìœ ì˜í•´ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    st.info("ChatGPTëŠ” ì‹¤ìˆ˜ë¥¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¤‘ìš”í•œ ì •ë³´ë¥¼ ë°˜ë“œì‹œ ì¶”ê°€ í™•ì¸í•˜ì„¸ìš”.")

    # ì‚¬ì´ë“œë°” ë¼ë””ì˜¤ ë²„íŠ¼ìœ¼ë¡œ íƒ­ êµ¬ë¶„
    tab = st.sidebar.radio("ë©”ë‰´ ì„ íƒ", ("GPT ì±„íŒ…", "DOCX ë¶„ì„", "ì»¤ë®¤ë‹ˆí‹°"))

    if tab == "GPT ì±„íŒ…":
        st.subheader("GPT-4 ì±„íŒ…")
        chat_interface()

    elif tab == "DOCX ë¶„ì„":
        st.subheader("DOCX ë¬¸ì„œ ë¶„ì„ (ê³ ê¸‰ Chunk ë‹¨ìœ„ ë¶„ì„)")
        uploaded_file = st.file_uploader(
            "DOCX íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (ë¬¸ì„œ ë‚´ì— '===Heading:'ì´ë¼ëŠ” êµ¬ë¶„ìë¥¼ ì¶”ê°€í•´ë³´ì„¸ìš”!)",
            type=['docx']
        )

        if uploaded_file is not None:
            filename = uploaded_file.name
            file_bytes = uploaded_file.getvalue()
            file_hash = hashlib.md5(file_bytes).hexdigest()

            # ìƒˆ íŒŒì¼ ì—…ë¡œë“œ ì‹œ ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
            if ("uploaded_file_hash" not in st.session_state or
                st.session_state.uploaded_file_hash != file_hash):
                st.session_state.uploaded_file_hash = file_hash
                st.session_state.extracted_text = ""
                st.session_state.summary = ""
                st.session_state.processed = False

            # ì•„ì§ ì²˜ë¦¬í•˜ì§€ ì•Šì•˜ë‹¤ë©´ í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ê³ ê¸‰ ë¶„ì„
            if not st.session_state.processed:
                raw_text = docx_to_text(uploaded_file)
                if raw_text.strip():
                    with st.spinner("ë¬¸ì„œ ê³ ê¸‰ ë¶„ì„ ì§„í–‰ ì¤‘..."):
                        advanced_summary = docx_advanced_processing(raw_text, language='korean')
                        st.session_state.summary = advanced_summary
                        st.session_state.extracted_text = raw_text
                        st.success("DOCX ê³ ê¸‰ ë¶„ì„ ì™„ë£Œ!")
                else:
                    st.error("DOCXì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    st.session_state.summary = ""

                st.session_state.processed = True

            # ê²°ê³¼ í‘œì‹œ
            if st.session_state.get("processed", False):
                if 'summary' in st.session_state and st.session_state.summary.strip():
                    st.write("## (ê³ ê¸‰) Chunk ê¸°ë°˜ ìš”ì•½ & ì¤‘ìš”ë„ ê²°ê³¼")
                    st.write(st.session_state.summary)
                else:
                    st.write("## ìš”ì•½ ê²°ê³¼ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    else:
        community_investment_tab()


if __name__ == "__main__":
    main()
