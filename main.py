import os
import streamlit as st
from io import BytesIO
from dotenv import load_dotenv
import pdfplumber
from pptx import Presentation
from langchain.chat_models import ChatOpenAI
from langchain.schema import HumanMessage
import openai
from pathlib import Path
import hashlib
import nltk
from PIL import Image
import pytesseract
import tempfile
import time

# pyhwp ëª¨ë“ˆ ì„í¬íŠ¸ ì‹œë„
try:
    import pyhwp
    HWP_SUPPORTED = True
except ModuleNotFoundError:
    HWP_SUPPORTED = False

# NLTK ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì„¤ì •
NLTK_DATA_DIR = os.path.expanduser("~/nltk_data")
os.makedirs(NLTK_DATA_DIR, exist_ok=True)
nltk.data.path.append(NLTK_DATA_DIR)
try:
    nltk.download('punkt', download_dir=NLTK_DATA_DIR)
    nltk.download('stopwords', download_dir=NLTK_DATA_DIR)
except FileExistsError:
    pass  # ì´ë¯¸ ë‹¤ìš´ë¡œë“œëœ ê²½ìš° ë¬´ì‹œ

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
dotenv_path = Path('.env')
load_dotenv(dotenv_path=dotenv_path)
openai_api_key = os.getenv("OPENAI_API_KEY")
if not openai_api_key:
    openai_api_key = st.sidebar.text_input("OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.", type="password")
    if not openai_api_key:
        st.error("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        st.stop()
openai.api_key = openai_api_key

# Streamlit ì´ˆê¸° ìƒíƒœ ì„¤ì •
if 'lang' not in st.session_state:
    st.session_state.lang = 'english'
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []
if 'extracted_text' not in st.session_state:
    st.session_state.extracted_text = ""
if 'gpt_questions' not in st.session_state:
    st.session_state.gpt_questions = []
if 'gpt_suggestions' not in st.session_state:
    st.session_state.gpt_suggestions = ""
if 'text_summary' not in st.session_state:
    st.session_state.text_summary = ""
if 'key_terms' not in st.session_state:
    st.session_state.key_terms = ""

st.title("ğŸ“š Study Helper with File Processing and Chat")
st.write("---")
st.warning("ì €ì‘ë¬¼ì„ ë¶ˆë²• ë³µì œí•˜ì—¬ ê²Œì‹œí•˜ëŠ” ê²½ìš° ë‹¹ì‚¬ëŠ” ì±…ì„ì§€ì§€ ì•Šìœ¼ë©°, ì €ì‘ê¶Œë²•ì— ìœ ì˜í•˜ì—¬ íŒŒì¼ì„ ì˜¬ë ¤ì£¼ì„¸ìš”.")

# ì±„íŒ… ê¸°ë¡ ì¶”ê°€ í•¨ìˆ˜
def add_chat_message(role, message):
    st.session_state.chat_history.append({"role": role, "message": message})

# ì–¸ì–´ ê°ì§€ í•¨ìˆ˜
def detect_language(text):
    if not text.strip():
        return "en"
    llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0, openai_api_key=openai_api_key)
    prompt = f"ë‹¤ìŒ í…ìŠ¤íŠ¸ì˜ ì–¸ì–´ë¥¼ ISO 639-1 ì½”ë“œë¡œ ê°ì§€í•´ ì£¼ì„¸ìš” (ì˜ˆ: 'en'ì€ ì˜ì–´, 'ko'ëŠ” í•œêµ­ì–´):\n\n{text[:500]}"
    messages = [HumanMessage(content=prompt)]
    try:
        response = llm(messages)
        language_code = response.content.strip().lower().split()[0]
        return language_code
    except Exception as e:
        st.error(f"ì–¸ì–´ ê°ì§€ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return "en"

# ChatGPT ì‘ë‹µ í•¨ìˆ˜
def ask_gpt_question(question, language):
    llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0.5, openai_api_key=openai_api_key)
    prompt = question if language == 'english' else f"ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µë³€: {question}"
    messages = [HumanMessage(content=prompt)]
    try:
        response = llm(messages)
        return response.content.strip()
    except openai.error.OpenAIError as e:
        st.error(f"API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return ""

# ìš”ì•½ ìƒì„± í•¨ìˆ˜
def generate_summary(extracted_text, language):
    llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0.5, openai_api_key=openai_api_key)
    prompt = (
        f"ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ì½ê³  ì„œë¡ , ë³¸ë¡ , ê²°ë¡ ìœ¼ë¡œ êµ¬ì„±ëœ ìš”ì•½ì„ ì‘ì„±í•´ ì£¼ì„¸ìš”:\n\n{extracted_text}"
        if language == 'korean'
        else f"Read the following text and write a summary with introduction, body, and conclusion:\n\n{extracted_text}"
    )
    messages = [HumanMessage(content=prompt)]
    try:
        response = llm(messages)
        return response.content.strip()
    except openai.error.OpenAIError as e:
        st.error(f"ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return ""

# í•µì‹¬ ë‹¨ì–´ ë¶„ì„ í•¨ìˆ˜
def extract_key_terms(extracted_text, language):
    llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0.5, openai_api_key=openai_api_key)
    prompt = (
        f"ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ ì¤‘ìš”í•œ í‚¤ì›Œë“œ 5~10ê°œë¥¼ ì¶”ì¶œí•˜ê³ , ê° í‚¤ì›Œë“œì˜ ê°„ë‹¨í•œ ì„¤ëª…ì„ ì‘ì„±í•´ ì£¼ì„¸ìš”:\n\n{extracted_text}"
        if language == 'korean'
        else f"Extract 5 to 10 key terms from the text and provide a brief description for each:\n\n{extracted_text}"
    )
    messages = [HumanMessage(content=prompt)]
    try:
        response = llm(messages)
        return response.content.strip()
    except openai.error.OpenAIError as e:
        st.error(f"í•µì‹¬ ë‹¨ì–´ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return ""

# í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ì²˜ë¦¬ í•¨ìˆ˜
def process_text(extracted_text):
    if not extracted_text.strip():
        st.error("íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    st.session_state.extracted_text = extracted_text
    language_code = detect_language(extracted_text)
    st.session_state.lang = 'korean' if language_code == 'ko' else 'english'
    st.write(f"### ê°ì§€ëœ ì–¸ì–´: {'í•œêµ­ì–´' if language_code == 'ko' else 'ì˜ì–´'}")

    with st.spinner("GPTê°€ ìš”ì•½ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
        summary = generate_summary(extracted_text, st.session_state.lang)
        st.session_state.text_summary = summary

    with st.spinner("GPTê°€ í•µì‹¬ ë‹¨ì–´ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
        key_terms = extract_key_terms(extracted_text, st.session_state.lang)
        st.session_state.key_terms = key_terms

    with st.spinner("GPTê°€ ì§ˆë¬¸ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
        questions = generate_gpt_questions(extracted_text, st.session_state.lang)
        st.session_state.gpt_questions = questions

    with st.spinner("GPTê°€ ì œì•ˆ ì‚¬í•­ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
        suggestions = generate_gpt_suggestions(extracted_text, st.session_state.lang)
        st.session_state.gpt_suggestions = suggestions

# GPTê°€ ì§ˆë¬¸ ìƒì„± í•¨ìˆ˜
def generate_gpt_questions(extracted_text, language):
    llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0.5, openai_api_key=openai_api_key)
    prompt = (
        f"ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ìê°€ ê¹Šì´ ìƒê°í•  ìˆ˜ ìˆëŠ” ì§ˆë¬¸ 3ê°œë¥¼ ì œì•ˆí•´ì£¼ì„¸ìš”:\n\n{extracted_text}"
        if language == 'korean'
        else f"Based on the following text, generate 3 thoughtful questions for deeper understanding:\n\n{extracted_text}"
    )
    messages = [HumanMessage(content=prompt)]
    try:
        response = llm(messages)
        questions = [q.strip() for q in response.content.strip().split('\n') if q.strip()]
        return questions
    except openai.error.OpenAIError as e:
        st.error(f"ì§ˆë¬¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return []

# GPTê°€ ì œì•ˆ ì‚¬í•­ ìƒì„± í•¨ìˆ˜
def generate_gpt_suggestions(extracted_text, language):
    llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0.5, openai_api_key=openai_api_key)
    prompt = (
        f"ë‹¤ìŒ í…ìŠ¤íŠ¸ì— ê¸°ë°˜í•˜ì—¬ ê°œì„ í•  ì ê³¼ ì£¼ìš” í†µì°°ì„ ì œì•ˆí•´ì£¼ì„¸ìš”:\n\n{extracted_text}"
        if language == 'korean'
        else f"Based on the following text, provide suggestions for improvement and key insights:\n\n{extracted_text}"
    )
    messages = [HumanMessage(content=prompt)]
    try:
        response = llm(messages)
        return response.content.strip()
    except openai.error.OpenAIError as e:
        st.error(f"ì œì•ˆ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return ""

# íŒŒì¼ ì—…ë¡œë“œ ì²˜ë¦¬
uploaded_file = st.file_uploader("íŒŒì¼ì„ ì˜¬ë ¤ì£¼ì„¸ìš” (PDF, PPTX, PNG, JPG, JPEG, HWP ì§€ì›)", type=['pdf', 'pptx', 'png', 'jpg', 'jpeg', 'hwp'])
if uploaded_file:
    extracted_text = ""
    file_type = uploaded_file.type
    if file_type == 'application/pdf':
        try:
            with pdfplumber.open(BytesIO(uploaded_file.getvalue())) as pdf:
                extracted_text = "\n".join([page.extract_text() or "" for page in pdf.pages])
        except Exception as e:
            st.error(f"PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
    elif file_type == 'application/vnd.openxmlformats-officedocument.presentationml.presentation':
        try:
            prs = Presentation(BytesIO(uploaded_file.getvalue()))
            extracted_text = "\n".join([shape.text for slide in prs.slides for shape in slide.shapes if hasattr(shape, "text")])
        except Exception as e:
            st.error(f"PPTXì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
    elif file_type.startswith('image/'):
        try:
            image = Image.open(uploaded_file)
            extracted_text = pytesseract.image_to_string(image, lang='kor+eng')
        except Exception as e:
            st.error(f"ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
    elif file_type == 'application/haansoft-hwp':
        if HWP_SUPPORTED:
            try:
                with tempfile.NamedTemporaryFile(delete=False, suffix='.hwp') as tmp:
                    tmp.write(uploaded_file.getvalue())
                    tmp_path = tmp.name
                doc = pyhwp.HwpDocument(tmp_path)
                extracted_text = doc.body_text or ""
            except Exception as e:
                st.error(f"HWP ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        else:
            st.error("HWP íŒŒì¼ ì²˜ë¦¬ë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. pyhwp ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
    else:
        st.error("ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤.")

    if extracted_text:
        process_text(extracted_text)

# ê²°ê³¼ ì¶œë ¥
if st.session_state.text_summary:
    st.write("## ìš”ì•½ ê²°ê³¼")
    st.write(st.session_state.text_summary)

if st.session_state.key_terms:
    st.write("## í•µì‹¬ ë‹¨ì–´ ë¶„ì„")
    st.write(st.session_state.key_terms)

if st.session_state.gpt_questions:
    st.write("## GPTê°€ ìƒì„±í•œ ì§ˆë¬¸")
    for question in st.session_state.gpt_questions:
        st.write(f"- {question}")

if st.session_state.gpt_suggestions:
    st.write("## GPTì˜ ì œì•ˆ ì‚¬í•­")
    st.write(st.session_state.gpt_suggestions)

# ì‚¬ìš©ì ì…ë ¥ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
def chat_interface():
    for chat in st.session_state.chat_history:
        if chat["role"] == "user":
            st.write(f"**ì‚¬ìš©ì**: {chat['message']}")
        else:
            st.write(f"**GPT**: {chat['message']}")

    user_input = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:")
    if user_input:
        add_chat_message("user", user_input)
        with st.spinner("GPTê°€ ì‘ë‹µ ì¤‘ì…ë‹ˆë‹¤..."):
            response = ask_gpt_question(user_input, st.session_state.lang)
            add_chat_message("assistant", response)
            st.write(f"**GPT**: {response}")

    st.write("âš ï¸ ChatGPTëŠ” ì‹¤ìˆ˜í•  ìˆ˜ ìˆìœ¼ë©°, ì •ë³´ê°€ í•­ìƒ ì •í™•í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¤‘ìš”í•œ ë‚´ìš©ì„ í™•ì¸í•˜ì„¸ìš”.")

chat_interface()
