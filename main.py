import os
import shutil
import streamlit as st
from io import BytesIO
from dotenv import load_dotenv
import pdfplumber
from pptx import Presentation
from langchain.chat_models import ChatOpenAI
from langchain.schema import HumanMessage
from langchain.callbacks import StreamingStdOutCallbackHandler
import openai
from pathlib import Path
import hashlib
import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from PIL import Image
import subprocess
import tempfile
import base64
import io

# docx2txt ì„¤ì¹˜ í™•ì¸
try:
    import docx2txt
    DOCX_ENABLED = True
except ImportError:
    DOCX_ENABLED = False

# PaddleOCR ì„¤ì¹˜ í™•ì¸
try:
    from paddleocr import PaddleOCR
    PADDLE_OCR_ENABLED = True
    # í•œêµ­ì–´ OCR
    ocr = PaddleOCR(lang='ko')  
except ImportError:
    PADDLE_OCR_ENABLED = False

# NLTK ë¦¬ì†ŒìŠ¤ ë‹¤ìš´ë¡œë“œ
nltk.download('punkt')
nltk.download('stopwords')

korean_stopwords = [
    'ì´', 'ê·¸', 'ì €', 'ê²ƒ', 'ìˆ˜', 'ë“±', 'ë“¤', 'ë°', 'ë”', 'ë¡œ', 'ë¥¼', 'ì—',
    'ì˜', 'ì€', 'ëŠ”', 'ê°€', 'ì™€', 'ê³¼', 'í•˜ë‹¤', 'ìˆë‹¤', 'ë˜ë‹¤', 'ì´ë‹¤',
    'ìœ¼ë¡œ', 'ì—ì„œ', 'ê¹Œì§€', 'ë¶€í„°', 'ê¹Œì§€', 'ë§Œ', 'í•˜ë‹¤', 'ê·¸ë¦¬ê³ ',
    'í•˜ì§€ë§Œ', 'ê·¸ëŸ¬ë‚˜'
]

dotenv_path = Path('.env')
load_dotenv(dotenv_path=dotenv_path)

openai_api_key = os.getenv("OPENAI_API_KEY")
if not openai_api_key:
    openai_api_key = st.sidebar.text_input("OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.", type="password")
    if not openai_api_key:
        st.error("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        st.stop()

openai.api_key = openai_api_key

# ---------------------------------------------------------------------
# ë©”ì¸ íƒ€ì´í‹€
# ---------------------------------------------------------------------
st.title("studyhelper + Ctrl+V Image Chat Demo")
st.write("---")

if 'lang' not in st.session_state:
    st.session_state.lang = 'english'

st.warning("ì €ì‘ë¬¼ì„ ë¶ˆë²• ë³µì œí•˜ì—¬ ê²Œì‹œí•˜ëŠ” ê²½ìš° ë‹¹ì‚¬ëŠ” ì±…ì„ì§€ì§€ ì•Šìœ¼ë©°, ì €ì‘ê¶Œë²•ì— ìœ ì˜í•˜ì—¬ íŒŒì¼ì„ ì˜¬ë ¤ì£¼ì„¸ìš”.")

# ì„¸ì…˜ ì´ˆê¸°í™”
if "processed" not in st.session_state:
    st.session_state.processed = False

# ------------------ ì±„íŒ… ê´€ë ¨ ì„¸ì…˜/í•¨ìˆ˜ ------------------
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# **pasted_image_b64**: JSì—ì„œ postMessageë¡œ ë„˜ê²¨ì¤„ Base64 ì´ë¯¸ì§€ë¥¼ ì„ì‹œ ì €ì¥
if "pasted_image_b64" not in st.session_state:
    st.session_state.pasted_image_b64 = None

def add_chat_message(role: str, content):
    """ì±„íŒ… ê¸°ë¡ì— ë©”ì‹œì§€ë¥¼ ì¶”ê°€. contentëŠ” str(í…ìŠ¤íŠ¸) ë˜ëŠ” PIL.Image"""
    st.session_state.chat_history.append({"role": role, "content": content})

def show_chat_history():
    """ì±„íŒ… ê¸°ë¡ í‘œì‹œ"""
    for msg in st.session_state.chat_history:
        if msg["role"] == "assistant":
            with st.chat_message("assistant"):
                if isinstance(msg["content"], str):
                    st.write(msg["content"])
                elif isinstance(msg["content"], Image.Image):
                    st.image(msg["content"])
        else:  # user
            with st.chat_message("user"):
                if isinstance(msg["content"], str):
                    st.write(msg["content"])
                elif isinstance(msg["content"], Image.Image):
                    st.image(msg["content"])

# ------------------ OCR & í…ìŠ¤íŠ¸ ì¶”ì¶œ í•¨ìˆ˜ë“¤ ------------------
def pdf_to_text(upload_file):
    try:
        with pdfplumber.open(BytesIO(upload_file.getvalue())) as pdf:
            pages = []
            for i, page in enumerate(pdf.pages):
                text = page.extract_text()
                if text:
                    pages.append(f"<PAGE{i+1}>\n{text}")
            return "\n".join(pages)
    except Exception as e:
        st.error(f"PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return ""

def pptx_to_text(upload_file):
    try:
        prs = Presentation(BytesIO(upload_file.getvalue()))
        text_runs = []
        for slide in prs.slides:
            for shape in slide.shapes:
                if hasattr(shape, "text"):
                    text_runs.append(shape.text)
        return "\n".join(text_runs)
    except Exception as e:
        st.error(f"PPTXì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return ""

def image_to_text(uploaded_image):
    """ì´ë¯¸ì§€ íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (PaddleOCR ì‚¬ìš©)"""
    if not PADDLE_OCR_ENABLED:
        st.warning("PaddleOCRê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•Šì€ í™˜ê²½ì…ë‹ˆë‹¤. ì´ë¯¸ì§€ í…ìŠ¤íŠ¸ ì¸ì‹ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return ""
    try:
        with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as tmp_img:
            image = Image.open(uploaded_image)
            image.save(tmp_img.name, format='PNG')
            tmp_path = tmp_img.name
        # OCR ìˆ˜í–‰
        result = ocr.ocr(tmp_path, cls=False)
        extracted_text = ""
        for line in result:
            for word_info in line:
                extracted_text += word_info[1][0] + "\n"
        os.remove(tmp_path)
        return extracted_text.strip()
    except Exception as e:
        st.warning(f"ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
        return ""

def hwp_to_text(upload_file):
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix='.hwp') as tmp:
            tmp.write(upload_file.getvalue())
            tmp_path = tmp.name
        result = subprocess.run(["hwp5txt", tmp_path], capture_output=True, text=True)
        if result.returncode == 0:
            return result.stdout
        else:
            st.error("HWPì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. hwp5txt íˆ´ì´ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
            return ""
    except FileNotFoundError:
        st.error("hwp5txt ëª…ë ¹ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. hwp5txtê°€ ì œëŒ€ë¡œ ì„¤ì¹˜ë˜ì–´ PATHì— í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return ""
    except Exception as e:
        st.error(f"HWP ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return ""

def docx_to_text(upload_file):
    if not DOCX_ENABLED:
        st.warning("docx2txtê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•Šì•„ .docx íŒŒì¼ì„ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return ""
    try:
        text = docx2txt.process(BytesIO(upload_file.getvalue()))
        return text if text else ""
    except Exception as e:
        st.error(f"DOCX íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return ""

def doc_to_text(upload_file):
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix='.doc') as tmp:
            tmp.write(upload_file.getvalue())
            tmp_path = tmp.name
        result = subprocess.run(["antiword", tmp_path], capture_output=True, text=True)
        if result.returncode == 0:
            return result.stdout
        else:
            st.error("DOCì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. antiword íˆ´ì´ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
            return ""
    except FileNotFoundError:
        st.error("antiword ëª…ë ¹ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. antiwordê°€ ì œëŒ€ë¡œ ì„¤ì¹˜ë˜ì–´ PATHì— í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return ""
    except Exception as e:
        st.error(f"DOC ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return ""

# ------------------ GPT í˜¸ì¶œ í•¨ìˆ˜ë“¤ ------------------
def ask_gpt_model(messages):
    llm = ChatOpenAI(
        model_name="gpt-4", 
        temperature=0,
        streaming=True, 
        callbacks=[StreamingStdOutCallbackHandler()]
    )
    response = llm(messages)
    return response.content

def detect_language(text):
    prompt = f"ë‹¤ìŒ í…ìŠ¤íŠ¸ì˜ ì–¸ì–´ë¥¼ ISO 639-1 ì½”ë“œë¡œ ê°ì§€í•´ ì£¼ì„¸ìš” (ì˜ˆ: 'en'ì€ ì˜ì–´, 'ko'ëŠ” í•œêµ­ì–´):\n\n{text[:500]}"
    messages = [HumanMessage(content=prompt)]
    return ask_gpt_model(messages).strip().lower().split()[0]

def summarize_text(text, language):
    if language == 'korean':
        prompt = f"ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ì½ê³  ì„œë¡ , ë³¸ë¡ , ê²°ë¡ ìœ¼ë¡œ êµ¬ì„±ëœ ìì„¸í•œ ìš”ì•½ì„ ì‘ì„±í•´ ì£¼ì„¸ìš”:\n\n{text}"
    else:
        prompt = f"Read the following text and write a detailed summary with introduction, main body, and conclusion:\n\n{text}"
    messages = [HumanMessage(content=prompt)]
    return ask_gpt_model(messages).strip()

def extract_key_summary_words_with_sources(text, language):
    if language == 'korean':
        prompt = f"""ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ ì¤‘ìš”í•œ í‚¤ì›Œë“œ 5~10ê°œë¥¼ ì¶”ì¶œí•˜ê³ , ê° í‚¤ì›Œë“œì˜ ì¶œì²˜ë¥¼ í‘œì‹œí•´ì£¼ì„¸ìš”.

í‚¤ì›Œë“œ1 (ì¶œì²˜)
í‚¤ì›Œë“œ2 (ì¶œì²˜)
...

í…ìŠ¤íŠ¸:
{text}"""
    else:
        prompt = f"""Extract 5 to 10 important keywords from the text and indicate their sources:

Keyword1 (Source)
Keyword2 (Source)
...

Text:
{text}"""
    messages = [HumanMessage(content=prompt)]
    return ask_gpt_model(messages).strip()

def extract_and_search_terms(summary_text, extracted_text, language='english'):
    if language == 'korean':
        prompt = f"ë‹¤ìŒ ìš”ì•½ì—ì„œ ì¤‘ìš”í•œ ìš©ì–´ 5~10ê°œë¥¼ ì¶”ì¶œí•˜ê³ , ê° ìš©ì–´ ì •ì˜ì™€ í…ìŠ¤íŠ¸ ë‚´ í˜ì´ì§€ ì •ë³´ë¥¼ ì œê³µ:\n\n{summary_text}"
    else:
        prompt = f"From the following summary, extract 5-10 important terms, provide detailed definitions and their page references:\n\n{summary_text}"
    messages = [HumanMessage(content=prompt)]
    return ask_gpt_model(messages).strip()

def generate_questions_for_user(text, language):
    if language == 'korean':
        prompt = f"ë‹¤ìŒ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ìê°€ ê¹Šì´ ìƒê°í•  ìˆ˜ ìˆëŠ” ì§ˆë¬¸ 3ê°œ ì œì‹œ:\n\n{text}"
    else:
        prompt = f"Based on the following content, generate 3 thoughtful questions for deeper understanding:\n\n{text}"
    messages = [HumanMessage(content=prompt)]
    raw_response = ask_gpt_model(messages)
    return [q.strip() for q in raw_response.strip().split('\n') if q.strip()]

def create_ppt_from_text(text, filename="summary_output.pptx"):
    prs = Presentation()
    title_slide_layout = prs.slides.add_slide(title_slide_layout)
    slide = prs.slides.add_slide(title_slide_layout)
    slide.shapes.title.text = "Summary"
    slide.placeholders[1].text = text

    buf = BytesIO()
    prs.save(buf)
    buf.seek(0)
    return buf

# ---------------------------------------------------------------------
# 1) ì±„íŒ…ì°½ UI (í…ìŠ¤íŠ¸ + Ctrl+V)
# ---------------------------------------------------------------------
# ì±„íŒ… ê¸°ë¡ í‘œì‹œ
show_chat_history()

# ìë°”ìŠ¤í¬ë¦½íŠ¸ ì‚½ì… (Ctrl+V -> paste event)
paste_js_code = """
<script>
document.addEventListener('paste', async (event) => {
    const items = (event.clipboardData || event.originalEvent.clipboardData).items;
    if (!items) return;
    for (let idx in items) {
        let item = items[idx];
        if (item.kind === 'file') {
            let blob = item.getAsFile();
            if (blob) {
                // blob -> base64
                const reader = new FileReader();
                reader.onload = function(e) {
                    const base64Data = e.target.result.split(',')[1];
                    // postMessageë¡œ streamlitì— ì „ì†¡
                    window.parent.postMessage(
                        { 
                          type: 'PASTE_IMAGE', 
                          base64: base64Data 
                        }, 
                        '*'
                    );
                };
                reader.readAsDataURL(blob);
            }
        }
    }
});
</script>
"""

# HTML ì»´í¬ë„ŒíŠ¸ ì‚½ì…
st.components.v1.html(paste_js_code, height=0)

st.info("**Ctrl+V**ë¡œ ì´ë¯¸ì§€ë¥¼ ë¶™ì—¬ë„£ì€ ë’¤, ì•„ë˜ â€˜ë¶™ì—¬ë„£ê¸° ì´ë¯¸ì§€ ì²˜ë¦¬â€™ ë²„íŠ¼ì„ ëˆ„ë¥´ì„¸ìš”. (ë°ëª¨)")

# (ì„ì‹œ) "ë¶™ì—¬ë„£ê¸° ì´ë¯¸ì§€ ì²˜ë¦¬" ë²„íŠ¼
def handle_pasted_image():
    """ì„¸ì…˜ì— ì €ì¥ëœ base64 -> PIL.Imageë¡œ ë³€í™˜í•˜ì—¬ ì±„íŒ…ì— ì¶”ê°€"""
    if st.session_state.pasted_image_b64:
        image_data = base64.b64decode(st.session_state.pasted_image_b64)
        image = Image.open(io.BytesIO(image_data))
        add_chat_message("user", image)
        add_chat_message("assistant", "Ctrl+Vë¡œ ì´ë¯¸ì§€ë¥¼ ì˜ ë°›ì•˜ìŠµë‹ˆë‹¤!")
        st.session_state.pasted_image_b64 = None

if st.button("ë¶™ì—¬ë„£ê¸° ì´ë¯¸ì§€ ì²˜ë¦¬"):
    handle_pasted_image()

# ì±„íŒ… í…ìŠ¤íŠ¸ ì…ë ¥
user_text = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...")
if user_text:
    add_chat_message("user", user_text)
    add_chat_message("assistant", f"ì‚¬ìš©ì ì…ë ¥: {user_text}")

# ì±„íŒ… ê¸°ë¡ ë‹¤ì‹œ í‘œì‹œ (ì—…ë°ì´íŠ¸ëœ ë‚´ìš© í¬í•¨)
show_chat_history()

# ---------------------------------------------------------------------
# 2) íŒŒì¼ ì—…ë¡œë“œ -> í…ìŠ¤íŠ¸ ì¶”ì¶œ -> GPT ë¶„ì„
# ---------------------------------------------------------------------
uploaded_file = st.file_uploader(
    "íŒŒì¼ ì—…ë¡œë“œ (PDF, PPTX, PNG, JPG, JPEG, HWP, DOC, DOCX)",
    type=['pdf', 'pptx', 'png', 'jpg', 'jpeg', 'hwp', 'doc', 'docx']
)

if uploaded_file is not None:
    filename = uploaded_file.name
    extension = os.path.splitext(filename)[1].lower()

    file_bytes = uploaded_file.getvalue()
    file_hash = hashlib.md5(file_bytes).hexdigest()

    # ì—…ë¡œë“œ íŒŒì¼ì´ ìƒˆë¡œ ë°”ë€Œì—ˆëŠ”ì§€ í™•ì¸
    if ("uploaded_file_hash" not in st.session_state or
        st.session_state.uploaded_file_hash != file_hash):
        st.session_state.uploaded_file_hash = file_hash
        st.session_state.extracted_text = ""
        st.session_state.summary = ""
        st.session_state.keywords = ""
        st.session_state.term_info = ""
        st.session_state.gpt_questions = []
        st.session_state.processed = False

    if not st.session_state.processed:
        if extension == ".pdf":
            extracted_text = pdf_to_text(uploaded_file)
        elif extension == ".pptx":
            extracted_text = pptx_to_text(uploaded_file)
        elif extension in [".png", ".jpg", ".jpeg"]:
            extracted_text = image_to_text(uploaded_file)
        elif extension == ".hwp":
            extracted_text = hwp_to_text(uploaded_file)
        elif extension == ".docx":
            extracted_text = docx_to_text(uploaded_file)
        elif extension == ".doc":
            extracted_text = doc_to_text(uploaded_file)
        else:
            st.error("ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤.")
            extracted_text = ""

        if not extracted_text.strip():
            st.error("ì—…ë¡œë“œëœ íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            st.session_state.summary = ""
        else:
            st.success("í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ!")
            language_code = detect_language(extracted_text)
            if language_code == 'ko':
                lang = 'korean'
                language_name = 'í•œêµ­ì–´'
            elif language_code == 'en':
                lang = 'english'
                language_name = 'ì˜ì–´'
            else:
                lang = 'english'
                language_name = 'ì•Œ ìˆ˜ ì—†ìŒ (ì˜ì–´ ì§„í–‰)'

            st.write(f"### ê°ì§€ëœ ì–¸ì–´: {language_name}")
            st.session_state.lang = lang
            st.session_state.extracted_text = extracted_text

            with st.spinner("ìš”ì•½ ìƒì„± ì¤‘..."):
                summary = summarize_text(extracted_text, lang)
                st.session_state.summary = summary

            with st.spinner("í•µì‹¬ ë‹¨ì–´ ì¶”ì¶œ ì¤‘..."):
                key_summary_words = extract_key_summary_words_with_sources(st.session_state.summary, lang)
                st.session_state.keywords = key_summary_words

            with st.spinner("ì¤‘ìš” ë‹¨ì–´ ì •ë³´ ì¶”ì¶œ ì¤‘..."):
                term_info = extract_and_search_terms(st.session_state.summary, extracted_text, language=lang)
                st.session_state.term_info = term_info

            with st.spinner("GPTê°€ ì§ˆë¬¸ì„ ìƒì„± ì¤‘..."):
                gpt_questions = generate_questions_for_user(extracted_text, lang)
                st.session_state.gpt_questions = gpt_questions

            st.session_state.processed = True

    if st.session_state.get("processed", False):
        # ê²°ê³¼ í‘œì‹œ
        if 'summary' in st.session_state and st.session_state.summary.strip():
            st.write("## ìš”ì•½ ê²°ê³¼")
            st.write(st.session_state.summary)
        else:
            st.write("## ìš”ì•½ ê²°ê³¼ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        if 'keywords' in st.session_state and st.session_state.keywords.strip():
            st.write("## í•µì‹¬ ìš”ì•½ ë‹¨ì–´ ë° ì¶œì²˜")
            st.write(st.session_state.keywords)

        if 'term_info' in st.session_state and st.session_state.term_info.strip():
            st.write("## ìš”ì•½ ë‚´ ì¤‘ìš”í•œ ë‹¨ì–´ ì •ë³´")
            st.write(st.session_state.term_info)

        st.write("---")
        if st.button("ìš”ì•½ ë‚´ìš©ì„ PPTë¡œ ë‹¤ìš´ë¡œë“œ"):
            ppt_buffer = create_ppt_from_text(st.session_state.summary)
            st.download_button(
                label="PPT ë‹¤ìš´ë¡œë“œ",
                data=ppt_buffer,
                file_name="summary_output.pptx",
                mime="application/vnd.openxmlformats-officedocument.presentationml.presentation"
            )

# ---------------------------------------------------------------------
# 3) í‚¤ì›Œë“œ ê²€ìƒ‰ & GPTê°€ ì‚¬ìš©ìì—ê²Œ ì§ˆë¬¸
# ---------------------------------------------------------------------
if st.session_state.get("processed", False):
    st.write("---")
    if st.session_state.lang == 'korean':
        st.write("## ğŸ” í‚¤ì›Œë“œ ê²€ìƒ‰")
        search_query = st.text_input("ê²€ìƒ‰í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”:")
    else:
        st.write("## ğŸ” Keyword Search")
        search_query = st.text_input("Enter a keyword to search:")

    if search_query:
        search_results = []
        for line in st.session_state.extracted_text.split('\n'):
            if search_query.lower() in line.lower():
                search_results.append(line.strip())
        if search_results:
            if st.session_state.lang == 'korean':
                st.write("### ê²€ìƒ‰ ê²°ê³¼:")
            else:
                st.write("### Search Results:")
            for result in search_results:
                st.write(f"- {result}")
        else:
            if st.session_state.lang == 'korean':
                st.write("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.write("No results found.")

if st.session_state.get("processed", False):
    st.write("---")
    if st.session_state.lang == 'korean':
        st.write("## GPTê°€ ë‹¹ì‹ ì—ê²Œ ì§ˆë¬¸í•©ë‹ˆë‹¤")
    else:
        st.write("## GPT has questions for you")

    if "gpt_questions" in st.session_state:
        for idx, question in enumerate(st.session_state.gpt_questions):
            user_answer = st.text_input(f"**{question}**", key=f"gpt_question_{idx}")
            if user_answer:
                with st.spinner("GPTê°€ ì‘ë‹µì„ ê²€í†  ì¤‘ì…ë‹ˆë‹¤..."):
                    if st.session_state.lang == 'korean':
                        feedback_prompt = f"{question}\n\nì‚¬ìš©ì ë‹µë³€: {user_answer}\n\ní”¼ë“œë°±ì„ ì œê³µí•´ ì£¼ì„¸ìš”."
                    else:
                        feedback_prompt = f"{question}\n\nUser's answer: {user_answer}\n\nPlease provide feedback on this."
                    feedback_answer = ask_gpt_model([HumanMessage(content=feedback_prompt)])
                    if st.session_state.lang == 'korean':
                        st.write("### GPTì˜ í”¼ë“œë°±")
                    else:
                        st.write("### GPT's Feedback")
                    st.write(feedback_answer)


# ---------------------------------------------------------------------
# ë§ˆì§€ë§‰ ì•ˆë‚´
# ---------------------------------------------------------------------
st.write("---")
st.info("""
**Ctrl+Vë¥¼ í†µí•´ ì´ë¯¸ì§€ë¥¼ ë¶™ì—¬ë„£ì€ ë’¤, 'ë¶™ì—¬ë„£ê¸° ì´ë¯¸ì§€ ì²˜ë¦¬' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.**  
ì´ëŠ” Streamlitì—ì„œ ê³µì‹ì ìœ¼ë¡œ ì§€ì›í•˜ì§€ ì•ŠëŠ” ê¸°ëŠ¥ì„ **ìë°”ìŠ¤í¬ë¦½íŠ¸ + postMessage**ë¡œ ê°„ë‹¨íˆ í‰ë‚´ ë‚¸ ì˜ˆì‹œì…ë‹ˆë‹¤.  
ì‹¤ì œ ì„œë¹„ìŠ¤ì—ì„œëŠ” **ì»¤ìŠ¤í…€ ì»´í¬ë„ŒíŠ¸**ë¡œ ë¸Œë¼ìš°ì €/íŒŒì´ì¬ ê°„ ì‹¤ì‹œê°„ í†µì‹ ì„ êµ¬ì„±í•´ì•¼ í•©ë‹ˆë‹¤.
""")
